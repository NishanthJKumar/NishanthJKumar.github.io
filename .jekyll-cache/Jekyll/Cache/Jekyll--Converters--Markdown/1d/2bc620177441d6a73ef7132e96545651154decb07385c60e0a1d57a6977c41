I"¨<p>Over winter break, I had the opportunity to write an extended abstract (my first first-author thing!) for an idea Iâ€™d been kicking around with some other members of my lab. We ended up submitting said abstract to VAM-HRI 2019: a workshop centered on Mixed-Reality for Human-Robot Interaction. Fortunately enough, our work got accepted (find it here!) and I had the incredible opportunity to miss a week of classes to attend Human-Robot Interaction 2019 in South Korea! This was my first ever robotics conference and what follows will be my thoughts from the conference, roughly organized as below:</p>

<ul>
  <li>Major takeaways + trends from HRI 2019</li>
  <li>Robot companies + demos!</li>
  <li>Overall thoughts</li>
  <li>Travelling in Korea + Misc.</li>
</ul>

<h1 id="major-takeaways-and-trends-from-hri-2019">Major Takeaways and Trends from HRI 2019</h1>
<h2 id="1-the-rise-of-virtual-augmented-and-mixed-reality">1. The rise of Virtual, Augmented and Mixed Reality</h2>
<p>I admit that this may be my own biased opinion. After all, my primary purpose behind going to this conference was to attend the VAM (Virtual, Augmented and Mixed-Reality) workshop where I myself had authored work that heavily relied on Mixed Reality. But, I was (pleasantly) surprised to see quite a few people that werenâ€™t just part of VAM-HRI actually use VR, AR or MR for things from robot learning to conducting experiments on social robots.</p>

<p><img src="/images/HRI-pics/AR_small.jpg" alt="AR Robot" class="align-center" /></p>

<p>Some used VR or AR for prototyping and design, and many others used it for experiments. Of particular interest was the fact that three different works attempted to use VAM technologies to facilitate robot Learning from Demonstration (LfD). Two of these focused on methods to build large-scale VR simulations of environments and tasks to collect a very large amount of training data from users via the internet.  This idea has been around for a while (there has even been some work from our lab about it!) but it was encouraging to see other people attempting to take it forward. Indeed, it would be incredible if we could have some sort of game where players could record themselves doing common tasks and we could then use these recordings to train a robot (in simulation) to do the same tasks (and hopefully eventually do them in real life!). The third LfD work was unique in that it proposed to use Mixed Reality holograms to provide constraints on demonstrations being collected. This was an incredibly fascinating (and apt!) use of MR for robot learning and I ended up tracking down the authors and attempting to pick their brains on how theyâ€™d come up with this idea and what they planned to do with it in the future.</p>

<p><img src="/images/HRI-pics/AR_prezi.jpg" alt="AR Prezi" class="align-center" /></p>

<p>Overall however, there were many more works that used VR, AR or MR than Iâ€™d expected. Earlier this year, some (smarter) lab members made me have the key realization that VR, AR and MR could act like new communication modalities between humans and robots. It was interesting and very exciting to see others realize this too and use these modalities in significant and unique ways!</p>
:ET