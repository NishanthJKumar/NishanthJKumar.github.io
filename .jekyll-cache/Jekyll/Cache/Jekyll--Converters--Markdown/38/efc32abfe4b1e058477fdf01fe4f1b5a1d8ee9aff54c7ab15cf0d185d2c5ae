I"¯<p style="text-align: center;font-size: 120%">Welcome to my Research page!</p>

<p style="text-align: center;font-size: 120%">Iâ€™m currently an Undergraduate Research Assistant in the <a href="https://h2r.cs.brown.edu/">Humans 2 Robots</a> and <a href="http://irl.cs.brown.edu/">Intelligent Robot</a> Labs at Brown University. I work within Brownâ€™s <a href="http://bigai.cs.brown.edu/">BigAI initiative</a> and am advised by Professors <a href="https://cs.brown.edu/people/stellex/">Stefanie Tellex</a>, <a href="http://cs.brown.edu/people/gdk/">George Konidaris</a> and <a href="http://cs.brown.edu/~mlittman/">Michael Littman</a>.</p>

<h2 id="research-interests">Research Interests</h2>
<p>Iâ€™m broadly interested in the fields of Artificial Intelligence (AI) and Robotics. More specifically, Iâ€™m drawn to the sub-fields of Reinforcement Learning, Deep Learning, Classical AI Planning, Representation and Heuristics for Planning and Mixed Reality for Robotics. Iâ€™m particularly interested in working towards intelligent, collaborative robots; which lies at the intersection of all my different interests.</p>

<p>My current work involves thinking about good representations for AI agents and enabling efficient planning within them. Specifically, Iâ€™m focusing on object-oriented representations and how their inherent structure can be used to speed-up decision making under uncertainty. I believe that creating representations that are both highly-structured while also being intuitive to humans will enable more sample-efficient and explainable AI.</p>

<p>Other current things Iâ€™m interested in / working on include Learning from Demonstrations (LfD) and Transfer Learning, and using Mixed Reality to enable robots to effectively collaborate with and acquire multi-modal knowledge from humans.</p>

<h2 id="publications">Publications</h2>
<h3 id="conference-papers">Conference Papers</h3>
<p><a href="https://h2r.cs.brown.edu/wp-content/uploads/wandzel19.pdf">Multi-Object Search using Object-Oriented POMDPs</a>.
Arthur Wandzel, Yoonseon Oh, Michael Fishman, <em>Nishanth Kumar</em>, Lawson L. S. Wong, and Stefanie Tellex
IEEE International Conference on Robotics and Automation (ICRA), 2019.</p>

<h3 id="worshop-papers-and-extended-abstracts">Worshop Papers and Extended Abstracts</h3>
<p>Task Scoping for Efficient Planning in Open Worlds
<em>Nishanth Kumar</em>*, Michael Fishman*, Natasha Danas, Michael Littman, Stefanie Tellex and George Konidaris. AAAI 2020 Student Abstract Workshop, New York, USA, February 2020.
[* denotes equal contribution]</p>

<p><a href="https://www.researchgate.net/publication/331563746_Knowledge_Acquisition_for_Robots_Through_Mixed_Reality_Head-Mounted_Displays">Knowledge Acquisition for Robots through Mixed Reality Head-Mounted Displays</a>.
<em>Nishanth Kumar</em>*, Eric Rosen* and Stefanie Tellex.
The Second International Workshop on Virtual, Augmented and Mixed Reality for Human Robot Interaction, Daegu, Korea March 2019.
[* denotes equal contribution]</p>

<h3 id="preprints">Preprints</h3>
<p><a href="https://arxiv.org/abs/1910.10628">Learning Deep Parameterized Skills from Demonstration for Re-targetable Visuomotor Control</a>
Jonathan Chang*, <em>Nishanth Kumar</em>*, Sean Hastings, Aaron Gokaslan, Diego Romeres, Devesh K. Jha, Daniel Nikovski, George Konidaris, Stefanie Tellex.
Preprint.
(Under Review RSS 2020)
[* denotes equal contribution. Work was done in collaboration with Mitsubishi Electric Research Laboratories]</p>
:ET